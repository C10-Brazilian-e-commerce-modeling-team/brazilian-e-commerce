{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we will use the data available to make sentiment analysis and predictive models around the satisfaction of the clients according to the use of the E-Commerce and the reviews of the purchases in order to improve the UX by the ofert available at the Marketplace.\n",
    "\n",
    "**References:**\n",
    "- [NLP](https://www.kaggle.com/code/thiagopanini/e-commerce-sentiment-analysis-eda-viz-nlp)\n",
    "- [Customer Satisfaction Prediction](https://www.kaggle.com/code/khakim17/custumer-satisfaction-prediction-and-analysist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# DataPrep\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import RSLPStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_id</th>\n",
       "      <th>order_id</th>\n",
       "      <th>review_score</th>\n",
       "      <th>review_comment_title</th>\n",
       "      <th>review_comment_message</th>\n",
       "      <th>review_creation_date</th>\n",
       "      <th>review_answer_timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7bc2406110b926393aa56f80a40eba40</td>\n",
       "      <td>73fc7af87114b39712e6da79b0a377eb</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018-01-18 00:00:00</td>\n",
       "      <td>2018-01-18 21:46:59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>80e641a11e56f04c1ad469d5645fdfde</td>\n",
       "      <td>a548910a1c6147796b98fdf73dbeba33</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018-03-10 00:00:00</td>\n",
       "      <td>2018-03-11 03:05:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>228ce5500dc1d8e020d8d1322874b6f0</td>\n",
       "      <td>f9e4b658b201a9f2ecdecbb34bed034b</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018-02-17 00:00:00</td>\n",
       "      <td>2018-02-18 14:36:24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>e64fb393e7b32834bb789ff8bb30750e</td>\n",
       "      <td>658677c97b385a9be170737859d3511b</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Recebi bem antes do prazo estipulado.</td>\n",
       "      <td>2017-04-21 00:00:00</td>\n",
       "      <td>2017-04-21 22:02:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>f7c4243c7fe1938f181bec41a392bdeb</td>\n",
       "      <td>8e6bfb81e283fa7e4f11123a3fb894f1</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Parabéns lojas lannister adorei comprar pela I...</td>\n",
       "      <td>2018-03-01 00:00:00</td>\n",
       "      <td>2018-03-02 10:26:53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99219</th>\n",
       "      <td>574ed12dd733e5fa530cfd4bbf39d7c9</td>\n",
       "      <td>2a8c23fee101d4d5662fa670396eb8da</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018-07-07 00:00:00</td>\n",
       "      <td>2018-07-14 17:18:30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99220</th>\n",
       "      <td>f3897127253a9592a73be9bdfdf4ed7a</td>\n",
       "      <td>22ec9f0669f784db00fa86d035cf8602</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2017-12-09 00:00:00</td>\n",
       "      <td>2017-12-11 20:06:42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99221</th>\n",
       "      <td>b3de70c89b1510c4cd3d0649fd302472</td>\n",
       "      <td>55d4004744368f5571d1f590031933e4</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Excelente mochila, entrega super rápida. Super...</td>\n",
       "      <td>2018-03-22 00:00:00</td>\n",
       "      <td>2018-03-23 09:10:43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99222</th>\n",
       "      <td>1adeb9d84d72fe4e337617733eb85149</td>\n",
       "      <td>7725825d039fc1f0ceb7635e3f7d9206</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018-07-01 00:00:00</td>\n",
       "      <td>2018-07-02 12:59:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99223</th>\n",
       "      <td>efe49f1d6f951dd88b51e6ccd4cc548f</td>\n",
       "      <td>90531360ecb1eec2a1fbb265a0db0508</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>meu produto chegou e ja tenho que devolver, po...</td>\n",
       "      <td>2017-07-03 00:00:00</td>\n",
       "      <td>2017-07-03 21:01:49</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>99224 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              review_id                          order_id  \\\n",
       "0      7bc2406110b926393aa56f80a40eba40  73fc7af87114b39712e6da79b0a377eb   \n",
       "1      80e641a11e56f04c1ad469d5645fdfde  a548910a1c6147796b98fdf73dbeba33   \n",
       "2      228ce5500dc1d8e020d8d1322874b6f0  f9e4b658b201a9f2ecdecbb34bed034b   \n",
       "3      e64fb393e7b32834bb789ff8bb30750e  658677c97b385a9be170737859d3511b   \n",
       "4      f7c4243c7fe1938f181bec41a392bdeb  8e6bfb81e283fa7e4f11123a3fb894f1   \n",
       "...                                 ...                               ...   \n",
       "99219  574ed12dd733e5fa530cfd4bbf39d7c9  2a8c23fee101d4d5662fa670396eb8da   \n",
       "99220  f3897127253a9592a73be9bdfdf4ed7a  22ec9f0669f784db00fa86d035cf8602   \n",
       "99221  b3de70c89b1510c4cd3d0649fd302472  55d4004744368f5571d1f590031933e4   \n",
       "99222  1adeb9d84d72fe4e337617733eb85149  7725825d039fc1f0ceb7635e3f7d9206   \n",
       "99223  efe49f1d6f951dd88b51e6ccd4cc548f  90531360ecb1eec2a1fbb265a0db0508   \n",
       "\n",
       "       review_score review_comment_title  \\\n",
       "0                 4                  NaN   \n",
       "1                 5                  NaN   \n",
       "2                 5                  NaN   \n",
       "3                 5                  NaN   \n",
       "4                 5                  NaN   \n",
       "...             ...                  ...   \n",
       "99219             5                  NaN   \n",
       "99220             5                  NaN   \n",
       "99221             5                  NaN   \n",
       "99222             4                  NaN   \n",
       "99223             1                  NaN   \n",
       "\n",
       "                                  review_comment_message review_creation_date  \\\n",
       "0                                                    NaN  2018-01-18 00:00:00   \n",
       "1                                                    NaN  2018-03-10 00:00:00   \n",
       "2                                                    NaN  2018-02-17 00:00:00   \n",
       "3                  Recebi bem antes do prazo estipulado.  2017-04-21 00:00:00   \n",
       "4      Parabéns lojas lannister adorei comprar pela I...  2018-03-01 00:00:00   \n",
       "...                                                  ...                  ...   \n",
       "99219                                                NaN  2018-07-07 00:00:00   \n",
       "99220                                                NaN  2017-12-09 00:00:00   \n",
       "99221  Excelente mochila, entrega super rápida. Super...  2018-03-22 00:00:00   \n",
       "99222                                                NaN  2018-07-01 00:00:00   \n",
       "99223  meu produto chegou e ja tenho que devolver, po...  2017-07-03 00:00:00   \n",
       "\n",
       "      review_answer_timestamp  \n",
       "0         2018-01-18 21:46:59  \n",
       "1         2018-03-11 03:05:13  \n",
       "2         2018-02-18 14:36:24  \n",
       "3         2017-04-21 22:02:06  \n",
       "4         2018-03-02 10:26:53  \n",
       "...                       ...  \n",
       "99219     2018-07-14 17:18:30  \n",
       "99220     2017-12-11 20:06:42  \n",
       "99221     2018-03-23 09:10:43  \n",
       "99222     2018-07-02 12:59:13  \n",
       "99223     2017-07-03 21:01:49  \n",
       "\n",
       "[99224 rows x 7 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews_df = pd.read_csv('datasets/order_reviews.csv')\n",
    "reviews_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (40977, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "      <th>comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>Recebi bem antes do prazo estipulado.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>Parabéns lojas lannister adorei comprar pela I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>aparelho eficiente. no site a marca do aparelh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Mas um pouco ,travando...pelo valor ta Boa.\\r\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Vendedor confiável, produto ok e entrega antes...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   score                                            comment\n",
       "0      5              Recebi bem antes do prazo estipulado.\n",
       "1      5  Parabéns lojas lannister adorei comprar pela I...\n",
       "2      4  aparelho eficiente. no site a marca do aparelh...\n",
       "3      4    Mas um pouco ,travando...pelo valor ta Boa.\\r\\n\n",
       "4      5  Vendedor confiável, produto ok e entrega antes..."
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_comments = reviews_df.loc[:, ['review_score', 'review_comment_message']]\n",
    "df_comments = df_comments.dropna(subset=['review_comment_message'])\n",
    "df_comments = df_comments.reset_index(drop=True)\n",
    "print(f'Dataset shape: {df_comments.shape}')\n",
    "df_comments.columns = ['score', 'comment']\n",
    "df_comments.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning the reviews with RegEx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the Stemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package rslp to\n",
      "[nltk_data]     C:\\Users\\000281268\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package rslp is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('rslp')\n",
    "from nltk.data import load\n",
    "from nltk.stem.api import StemmerI\n",
    "\n",
    "\n",
    "class RSLPStemmer(StemmerI):\n",
    "    \"\"\"\n",
    "    A stemmer for Portuguese.\n",
    "\n",
    "        >>> from nltk.stem import RSLPStemmer\n",
    "        >>> st = RSLPStemmer()\n",
    "        >>> # opening lines of Erico Verissimo's \"Música ao Longe\"\n",
    "        >>> text = '''\n",
    "        ... Clarissa risca com giz no quadro-negro a paisagem que os alunos\n",
    "        ... devem copiar . Uma casinha de porta e janela , em cima duma\n",
    "        ... coxilha .'''\n",
    "        >>> for token in text.split():\n",
    "        ...     print(st.stem(token))\n",
    "        clariss risc com giz no quadro-negr a pais que os alun dev copi .\n",
    "        uma cas de port e janel , em cim dum coxilh .\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self._model = []\n",
    "\n",
    "        self._model.append(self.read_rule(\"step0.pt\"))\n",
    "        self._model.append(self.read_rule(\"step1.pt\"))\n",
    "        self._model.append(self.read_rule(\"step2.pt\"))\n",
    "        self._model.append(self.read_rule(\"step3.pt\"))\n",
    "        self._model.append(self.read_rule(\"step4.pt\"))\n",
    "        self._model.append(self.read_rule(\"step5.pt\"))\n",
    "        self._model.append(self.read_rule(\"step6.pt\"))\n",
    "\n",
    "\n",
    "    def read_rule(self, filename):\n",
    "        rules = load(\"nltk:stemmers/rslp/\" + filename, format=\"raw\").decode(\"utf8\")\n",
    "        lines = rules.split(\"\\n\")\n",
    "\n",
    "        lines = [line for line in lines if line != \"\"]  # remove blank lines\n",
    "        lines = [line for line in lines if line[0] != \"#\"]  # remove comments\n",
    "\n",
    "        # NOTE: a simple but ugly hack to make this parser happy with double '\\t's\n",
    "        lines = [line.replace(\"\\t\\t\", \"\\t\") for line in lines]\n",
    "\n",
    "        # parse rules\n",
    "        rules = []\n",
    "        for line in lines:\n",
    "            rule = []\n",
    "            tokens = line.split(\"\\t\")\n",
    "\n",
    "            # text to be searched for at the end of the string\n",
    "            rule.append(tokens[0][1:-1])  # remove quotes\n",
    "\n",
    "            # minimum stem size to perform the replacement\n",
    "            rule.append(int(tokens[1]))\n",
    "\n",
    "            # text to be replaced into\n",
    "            rule.append(tokens[2][1:-1])  # remove quotes\n",
    "\n",
    "            # exceptions to this rule\n",
    "            rule.append([token[1:-1] for token in tokens[3].split(\",\")])\n",
    "\n",
    "            # append to the results\n",
    "            rules.append(rule)\n",
    "\n",
    "        return rules\n",
    "\n",
    "\n",
    "    def stem(self, word):\n",
    "        word = word.lower()\n",
    "\n",
    "        # the word ends in 's'? apply rule for plural reduction\n",
    "        if word[-1] == \"s\":\n",
    "            word = self.apply_rule(word, 0)\n",
    "\n",
    "        # the word ends in 'a'? apply rule for feminine reduction\n",
    "        if word[-1] == \"a\":\n",
    "            word = self.apply_rule(word, 1)\n",
    "\n",
    "        # augmentative reduction\n",
    "        word = self.apply_rule(word, 3)\n",
    "\n",
    "        # adverb reduction\n",
    "        word = self.apply_rule(word, 2)\n",
    "\n",
    "        # noun reduction\n",
    "        prev_word = word\n",
    "        word = self.apply_rule(word, 4)\n",
    "        if word == prev_word:\n",
    "            # verb reduction\n",
    "            prev_word = word\n",
    "            word = self.apply_rule(word, 5)\n",
    "            if word == prev_word:\n",
    "                # vowel removal\n",
    "                word = self.apply_rule(word, 6)\n",
    "\n",
    "        return word\n",
    "\n",
    "\n",
    "    def apply_rule(self, word, rule_index):\n",
    "        rules = self._model[rule_index]\n",
    "        for rule in rules:\n",
    "            suffix_length = len(rule[0])\n",
    "            if word[-suffix_length:] == rule[0]:  # if suffix matches\n",
    "                if len(word) >= suffix_length + rule[1]:  # if we have minimum size\n",
    "                    if word not in rule[3]:  # if not an exception\n",
    "                        word = word[:-suffix_length] + rule[2]\n",
    "                        break\n",
    "\n",
    "        return word"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions to clean the data with RegEx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_step_result(df_before,df_after, idx_list):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "    ----------\n",
    "    df_before: dataframe before preprocessing [type: dataframe]\n",
    "    df_after: dataframe after preprocessing [type: dataframe]\n",
    "    idx_list: list with the index of dataframes to compare [type: list]\n",
    "    \"\"\"\n",
    "    for i in idx_list:\n",
    "        print(f'{i}')\n",
    "        print(f'Before:\\n{df_before[i]}')\n",
    "        print(f'After:\\n{df_after[i]}')\n",
    "        print('\\n')\n",
    "def re_breakline(text_list):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "    ----------\n",
    "    text_list: list object with text content to be prepared [type: list]\n",
    "    \"\"\"\n",
    "    \n",
    "    # Applying regex\n",
    "    return [re.sub('[\\n\\r]', ' ', r) for r in text_list]\n",
    "\n",
    "def re_hiperlinks(text_list):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "    ----------\n",
    "    text_list: list object with text content to be prepared [type: list]\n",
    "    \"\"\"\n",
    "    \n",
    "    # Applying regex\n",
    "    pattern = 'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+'\n",
    "    return [re.sub(pattern, ' link ', r) for r in text_list]\n",
    "\n",
    "def re_dates(text_list):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "    ----------\n",
    "    text_list: list object with text content to be prepared [type: list]\n",
    "    \"\"\"\n",
    "    \n",
    "    # Applying regex\n",
    "    pattern = '([0-2][0-9]|(3)[0-1])(\\/|\\.)(((0)[0-9])|((1)[0-2]))(\\/|\\.)\\d{2,4}'\n",
    "    return [re.sub(pattern, ' data ', r) for r in text_list]\n",
    "\n",
    "def re_money(text_list):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "    ----------\n",
    "    text_list: list object with text content to be prepared [type: list]\n",
    "    \"\"\"\n",
    "    \n",
    "    # Applying regex\n",
    "    pattern = '[R]{0,1}\\$[ ]{0,}\\d+(,|\\.)\\d+'\n",
    "    return [re.sub(pattern, ' dinheiro ', r) for r in text_list]\n",
    "\n",
    "def re_numbers(text_list):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "    ----------\n",
    "    text_series: list object with text content to be prepared [type: list]\n",
    "    \"\"\"\n",
    "    \n",
    "    # Applying regex\n",
    "    return [re.sub('[0-9]+', ' numero ', r) for r in text_list]\n",
    "\n",
    "def re_negation(text_list):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "    ----------\n",
    "    text_series: list object with text content to be prepared [type: list]\n",
    "    \"\"\"\n",
    "    \n",
    "    # Applying regex\n",
    "    return [re.sub('([nN][ãÃaA][oO]|[ñÑ]| [nN] )', ' negação ', r) for r in text_list]\n",
    "\n",
    "def re_special_chars(text_list):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "    ----------\n",
    "    text_series: list object with text content to be prepared [type: list]\n",
    "    \"\"\"\n",
    "    \n",
    "    # Applying regex\n",
    "    return [re.sub('\\W', ' ', r) for r in text_list]\n",
    "\n",
    "def re_whitespaces(text_list):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "    ----------\n",
    "    text_series: list object with text content to be prepared [type: list]\n",
    "    \"\"\"\n",
    "    \n",
    "    # Applying regex\n",
    "    white_spaces = [re.sub('\\s+', ' ', r) for r in text_list]\n",
    "    white_spaces_end = [re.sub('[ \\t]+$', '', r) for r in white_spaces]\n",
    "    return white_spaces_end\n",
    "\n",
    "# Defining a function to remove the stopwords and to lower the comments\n",
    "pt_stopwords = stopwords.words('portuguese')\n",
    "def stopwords_removal(text, cached_stopwords=stopwords.words('portuguese')):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "    ----------\n",
    "    text: list object where the stopwords will be removed [type: list]\n",
    "    cached_stopwords: stopwords to be applied on the process [type: list, default: stopwords.words('portuguese')]\n",
    "    \"\"\"\n",
    "    \n",
    "    return [c.lower() for c in text.split() if c.lower() not in cached_stopwords]\n",
    "\n",
    "# Defining a function to remove the stopwords and to lower the comments\n",
    "def stemming_process(text, stemmer=RSLPStemmer()):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "    ----------\n",
    "    text: list object where the stopwords will be removed [type: list]\n",
    "    stemmer: type of stemmer to be applied [type: class, default: RSLPStemmer()]\n",
    "    \"\"\"\n",
    "    \n",
    "    return [stemmer.stem(c) for c in text.split()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning process and results verification "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a list of comment reviews\n",
    "reviews = list(df_comments['comment'].values)\n",
    "\n",
    "reviews_breakline = re_breakline(reviews)\n",
    "df_comments['re_breakline'] = reviews_breakline\n",
    "# Verifying results\n",
    "#print_step_result(reviews, reviews_breakline, idx_list=[48])\n",
    "\n",
    "reviews_hiperlinks = re_hiperlinks(reviews_breakline)\n",
    "df_comments['re_hiperlinks'] = reviews_hiperlinks\n",
    "#print_step_result(reviews_breakline, reviews_hiperlinks, idx_list=[10607])\n",
    "\n",
    "reviews_dates = re_dates(reviews_hiperlinks)\n",
    "df_comments['re_dates'] = reviews_dates\n",
    "# Verifying results\n",
    "#print_step_result(reviews_hiperlinks, reviews_dates, idx_list=[26161, 40729, 40901])\n",
    "\n",
    "reviews_money = re_money(reviews_dates)\n",
    "df_comments['re_money'] = reviews_money\n",
    "# Verifying results\n",
    "#print_step_result(reviews_dates, reviews_money, idx_list=[25533, 32667, 32370])\n",
    "\n",
    "reviews_numbers = re_numbers(reviews_money)\n",
    "df_comments['re_numbers'] = reviews_numbers\n",
    "# Verifying results\n",
    "#print_step_result(reviews_money, reviews_numbers, idx_list=[68])\n",
    "\n",
    "reviews_negation = re_negation(reviews_numbers)\n",
    "df_comments['re_negation'] = reviews_negation\n",
    "# Verifying results\n",
    "#print_step_result(reviews_numbers, reviews_negation, idx_list=[4703, 4549, 4773, 4820])\n",
    "\n",
    "reviews_special_chars = re_special_chars(reviews_negation)\n",
    "df_comments['re_special_chars'] = reviews_special_chars\n",
    "# Verifying results\n",
    "#print_step_result(reviews_negation, reviews_special_chars, idx_list=[45, 1165, 17579])\n",
    "\n",
    "reviews_whitespaces = re_whitespaces(reviews_special_chars)\n",
    "df_comments['re_whitespaces'] = reviews_whitespaces\n",
    "# Verifying results\n",
    "#print_step_result(reviews_special_chars, reviews_whitespaces, idx_list=[66, 121, 5602])\n",
    "\n",
    "reviews_stopwords = [' '.join(stopwords_removal(review)) for review in reviews_whitespaces]\n",
    "df_comments['stopwords_removed'] = reviews_stopwords\n",
    "# Verifying results\n",
    "#print_step_result(reviews_whitespaces, reviews_stopwords, idx_list=[108, 13646, 6563])\n",
    "\n",
    "reviews_stemmer = [' '.join(stemming_process(review)) for review in reviews_stopwords]\n",
    "df_comments['stemming'] = reviews_stemmer\n",
    "# Verifying results\n",
    "#print_step_result(reviews_stopwords, reviews_stemmer, idx_list=[0, 45, -1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[29272]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this list comprehension helps us to check reviews with complex words to test the regex, returning a list of indexes\n",
    "[reviews_hiperlinks.index(s) for s in reviews_hiperlinks if \" 😡 \" in s]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9acbe0c2570326cde3c50dfb23c7d06ed533d473ffb09e74a51e601ec6315934"
  },
  "kernelspec": {
   "display_name": "Python 3.10.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
